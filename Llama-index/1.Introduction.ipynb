{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmuxhD9ORwWPFUJEB0zH8m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamurAIGPT/LlamaIndex-course/blob/main/introduction/Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to LlamaIndex\n",
        "\n",
        "This is the first lesson of LlamaIndex course hosted at https://github.com/SamurAIGPT/LlamaIndex-course\n",
        "\n",
        "During the course, we will understand the basics of LlamaIndex, Data connectors what is an index, retrievers, query engines and finally build projects using LlamaIndex\n",
        "\n",
        "### What does LlamaIndex do?\n",
        "\n",
        "ChatGPT is trained on huge amounts of data. But what if you wish to train ChatGPT on your private data. There are 3 ways in which you can achieve this\n",
        "\n",
        "1. Train an open-source LLM like Llama on your data. This is a complex and time taking process which is not scalable\n",
        "2. Pass all of your documents as prompt to LLM. This has limitations since the context window size is limited \n",
        "3. Fetch and pass only the relevant documents as input to your LLM\n",
        "\n",
        "LlamaIndex works using the 3rd method and we will study how we can do that with the help of an example. Some of the concepts being covered by Index etc. will be covered in more detail in the upcoming lessons"
      ],
      "metadata": {
        "id": "uvfI4x-FGYBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training ChatGPT over your documents\n",
        "\n",
        "Here is a simple example of how you can train ChatGPT over your documents\n",
        "\n"
      ],
      "metadata": {
        "id": "PprJZxFWJLsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install LlamaIndex and dependencies"
      ],
      "metadata": {
        "id": "Kb4CHvZzgD2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index"
      ],
      "metadata": {
        "id": "2hv7H-NNf-aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the data to train on. We use state of the union text document to train over ChatGPT"
      ],
      "metadata": {
        "id": "VsmhVpUWgKz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/hwchase17/chat-your-data/master/state_of_the_union.txt\n",
        "!mkdir data\n",
        "!mv state_of_the_union.txt data/"
      ],
      "metadata": {
        "id": "N_f9DWSKKMQn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the chatbot using LlamaIndex\n",
        "\n",
        "Now comes the main part. We will use LlamaIndex to train ChatGPT over our private data. Some of the concepts mentioned here like VectorStoreIndex will be explained in further detail in upcoming lesson\n",
        "\n",
        "We are using Simple directory data reader from LlalaIndex to read the data from above downloaded file. This reader can read data from all the files in a directory and convert it into documents format which can be trained\n",
        "\n",
        "Place your openai key in place of \"YOUR KEY\""
      ],
      "metadata": {
        "id": "6c63r8FUgUhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "import openai\n",
        "openai.api_key = \"YOUR KEY\"\n",
        "documents = SimpleDirectoryReader('data').load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "id": "xZR0-cONKbA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we create a LlamaIndex interface called query engine to query our documents. Again this will be explained in more detail in upcoming lessons. \n",
        "\n",
        "With this you can now query over your data in natural language"
      ],
      "metadata": {
        "id": "ZcgozDyQhJYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"What is NATO?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYVIi5k4Konx",
        "outputId": "725140be-cc51-4ef4-959e-783e4de0ebd3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NATO is the North Atlantic Treaty Organization, an intergovernmental military alliance between 29 North American and European countries. It was created to secure peace and stability in Europe after World War 2.\n"
          ]
        }
      ]
    }
  ]
}