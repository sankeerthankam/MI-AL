{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/SamurAIGPT/LlamaIndex-course/blob/main/introduction/Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","source":["# Introduction to LlamaIndex\n","\n","### What does LlamaIndex do?\n","\n","ChatGPT is trained on huge amounts of data. But what if you want to train ChatGPT on your private data, there are 3 ways in which you can achieve this\n","\n","1. Train an open-source LLM like Llama on your data. (This is a complex and time taking process which is not scalable)\n","2. Pass all of your documents as prompt to LLM. (This has limitations since the context window size is limited)\n","3. Fetch and pass only the relevant documents as input to your LLM\n","\n","LlamaIndex works using the 3rd method and we will work on how we can do that with the help of an example. Some of the concepts of LLM that we will use are Data connectors, indexes, retrievers, query engines, etc."],"metadata":{"id":"uvfI4x-FGYBI"}},{"cell_type":"markdown","source":["### Training ChatGPT over your documents\n","\n","Here is an example of how you can train ChatGPT over your documents\n","\n"],"metadata":{"id":"PprJZxFWJLsW"}},{"cell_type":"markdown","source":["### Install LlamaIndex and dependencies"],"metadata":{"id":"Kb4CHvZzgD2Z"}},{"cell_type":"code","source":["!pip install llama_index"],"metadata":{"id":"2hv7H-NNf-aA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690200872824,"user_tz":-330,"elapsed":17019,"user":{"displayName":"Sankeerth A","userId":"02548847503148084862"}},"outputId":"5913d438-dca1-4571-ce14-5906a731bed4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting llama_index\n","  Downloading llama_index-0.7.11.post1-py3-none-any.whl (609 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m609.4/609.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tiktoken (from llama_index)\n","  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dataclasses-json (from llama_index)\n","  Downloading dataclasses_json-0.5.13-py3-none-any.whl (26 kB)\n","Collecting langchain>=0.0.218 (from llama_index)\n","  Downloading langchain-0.0.240-py3-none-any.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sqlalchemy>=2.0.15 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2.0.19)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.22.4)\n","Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (8.2.2)\n","Collecting openai>=0.26.4 (from llama_index)\n","  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.5.3)\n","Requirement already satisfied: urllib3<2 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.26.16)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2023.6.0)\n","Collecting typing-inspect>=0.8.0 (from llama_index)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (4.7.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from llama_index) (4.11.2)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.5.6)\n","Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (6.0.1)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (3.8.4)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (4.0.2)\n","Collecting langsmith<0.1.0,>=0.0.11 (from langchain>=0.0.218->llama_index)\n","  Downloading langsmith-0.0.14-py3-none-any.whl (29 kB)\n","Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (2.8.4)\n","Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain>=0.0.218->llama_index)\n","  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (1.10.11)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (2.27.1)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama_index)\n","  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai>=0.26.4->llama_index) (4.65.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0.15->llama_index) (2.0.2)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama_index)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->llama_index) (2.4.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2022.7.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llama_index) (2022.10.31)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (1.3.1)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama_index) (23.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama_index) (1.16.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.218->llama_index) (2023.5.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.218->llama_index) (3.4)\n","Installing collected packages: mypy-extensions, marshmallow, typing-inspect, tiktoken, openapi-schema-pydantic, langsmith, openai, dataclasses-json, langchain, llama_index\n","Successfully installed dataclasses-json-0.5.13 langchain-0.0.240 langsmith-0.0.14 llama_index-0.7.11.post1 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-0.27.8 openapi-schema-pydantic-1.2.4 tiktoken-0.4.0 typing-inspect-0.9.0\n"]}]},{"cell_type":"markdown","source":["### Download the data to train on. We use state of the union text document to train over ChatGPT"],"metadata":{"id":"VsmhVpUWgKz9"}},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/hwchase17/chat-your-data/master/state_of_the_union.txt\n","!mkdir data\n","!mv state_of_the_union.txt data/"],"metadata":{"id":"N_f9DWSKKMQn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690200883741,"user_tz":-330,"elapsed":1072,"user":{"displayName":"Sankeerth A","userId":"02548847503148084862"}},"outputId":"b32cb0f9-0d73-4e7f-a79d-40794b1cd999"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-07-24 12:14:42--  https://raw.githubusercontent.com/hwchase17/chat-your-data/master/state_of_the_union.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 39027 (38K) [text/plain]\n","Saving to: ‘state_of_the_union.txt’\n","\n","state_of_the_union. 100%[===================>]  38.11K  --.-KB/s    in 0.002s  \n","\n","2023-07-24 12:14:42 (16.6 MB/s) - ‘state_of_the_union.txt’ saved [39027/39027]\n","\n"]}]},{"cell_type":"markdown","source":["### Train the chatbot using LlamaIndex\n","\n","Now we will use LlamaIndex to train ChatGPT over our private data.\n","\n","We are using Simple directory data reader from LlalaIndex to read the data from above downloaded file. This reader can read data from all the files in a directory and convert it into documents format which can be trained\n","\n","Place your openai key in place of \"OPEN-AI-KEY\""],"metadata":{"id":"6c63r8FUgUhN"}},{"cell_type":"code","source":["from llama_index import VectorStoreIndex, SimpleDirectoryReader\n","import openai\n","openai.api_key = \"OPEN-AI-KEY\"\n","# openai.api_key = \"18**HAWiy\"\n","documents = SimpleDirectoryReader('data').load_data()\n","index = VectorStoreIndex.from_documents(documents)"],"metadata":{"id":"xZR0-cONKbA-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we create a LlamaIndex interface called query engine to query our documents.\n","\n","With this you can now query over your data in natural language"],"metadata":{"id":"ZcgozDyQhJYr"}},{"cell_type":"code","source":["query_engine = index.as_query_engine()\n","response = query_engine.query(\"What is NATO?\")\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hYVIi5k4Konx","outputId":"725140be-cc51-4ef4-959e-783e4de0ebd3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","NATO is the North Atlantic Treaty Organization, an intergovernmental military alliance between 29 North American and European countries. It was created to secure peace and stability in Europe after World War 2.\n"]}]}]}